---
title: 当"用AI"变成"依赖AI"——我是如何悄悄失去独立思考能力的
tags: [ AI, 人生 ]
categories: [ 编程人生, AI ]
date: 2026-02-20 02:19:38
---

## 一个让我警觉的瞬间

前几周，我在做一个相对普通的系统设计决策——选择用哪种缓存失效策略。这类问题我过去闭着眼睛都能推导出来，有时候在洗澡的时候就想清楚了。

但那天，我下意识地打开了Claude，把问题贴了进去。

等AI回答的那十几秒里，我突然意识到：我没有先想。我甚至没有给自己的大脑留出思考的空间，就直接去问AI了。

这让我感到一种隐隐的不安。

<!-- more -->

## 三个阶段：从工具到拐杖

回顾过去一年半使用AI编程工具的历程，我大致经历了三个阶段：

**第一阶段：好奇尝鲜**。用GitHub Copilot做代码补全，偶尔觉得"哇这个挺准的"，但整体还是自己主导思路，AI只是个聪明一点的自动补全。

**第二阶段：效率加速**。开始用AI生成单元测试、写样板代码、做代码review前的自查。这个阶段很爽，生产力明显提升，感觉捡到了宝。

**第三阶段：深度依赖**。用Claude Code、OpenCode，几个prompt就能完成过去需要几周的工作。质量有时候甚至超过手写。这是我现在的状态——也是问题开始的地方。

从第二阶段到第三阶段的跨越很丝滑，我几乎没有察觉到临界点在哪里。直到那个"没有先想就先问"的瞬间，我才回过头来审视：**我在这个过程中失去了什么？**

---

## 思维惰性的三种表现

### 1. 问题还没想清楚，就急着问AI

以前遇到技术难题，我的第一反应是在脑子里转几圈：问题的本质是什么？有哪些约束条件？有没有类似的先例？

现在，这个"先想"的步骤越来越短，有时候几乎为零。我直接把问题扔给AI，然后被动地接收答案。

这看起来像是在节省时间，但实际上我在跳过一个极其宝贵的过程——**用自己的认知框架消化问题**。那个过程慢，但它会在脑子里留下东西。AI给的答案，往往看完就忘。

### 2. 对AI输出失去了批判性审视

最开始用AI，我会仔细验证每一行代码，质疑每一个设计建议。现在，面对一个流畅、结构清晰、措辞自信的AI回答，我越来越容易直接点"接受"。

这是一种很隐蔽的认知偷懒。AI的回答有时候是对的，有时候是"看起来对的"，而我区分这两者的能力，正在因为使用频率降低而退化。

有一次我让AI帮我优化一段分布式锁的实现，它给的方案语法正确、逻辑自洽，我几乎要直接合进去了——但在最后一刻我停下来仔细看，发现它对某个边界竞态条件的处理存在微妙的问题。如果当时我处于完全的"接受模式"，这个bug就进代码库了。

### 3. 深度推理能力的钝化

有些技术洞察，是需要你坐下来，对着一张白纸或者一块白板，用自己的语言把系统从头推导一遍才能得到的。这个过程很痛苦，会卡住，会绕弯路，但正是这些卡顿和弯路，让知识真正沉淀下来。

现在我发现，当我需要做这种深度推理的时候，我的大脑"撑不住"的时间越来越短。我会更快地感到不耐烦，然后转而寻求AI的帮助。就像一块因为很少被锻炼而慢慢弱化的肌肉。

---

## 为什么这件事比它看起来更严重

有人可能会说：这有什么关系？用AI提高效率不是好事吗？未来AI会做的事情越来越多，我们顺势而为不就好了？

我部分同意这个观点，但我认为它低估了一件事：**深度思考能力不只是生产工具，它是判断力的来源。**

我在工作中做广告系统优化时，很多关键决策——比如如何设计预算分配算法、如何在系统故障时保证投放稳定性——不是"问一下AI"就能解决的。它需要我对整个业务上下文、技术约束、用户体验之间的张力有直觉性的理解。而这种直觉，是靠长期的独立思考积累出来的，不是靠消费AI答案积累的。

更深层的问题是：**当我越来越少地自己推导，我其实也在越来越少地建立真正属于自己的认知模型。** 我变得更像一个AI输出的"整合者"，而不是一个独立的技术思考者。

这对于初级工程师来说尤其危险。如果一个人在积累基础认知储备的阶段就深度依赖AI，他可能永远无法建立起那个能帮助他判断AI对错的内部参照系。

---

## 我正在尝试做的调整

我没有打算减少使用AI——那既不现实，也不聪明。但我在有意识地改变使用方式：

**先思考，再提问。** 现在我给自己一个规则：遇到问题，先在脑子里（或纸上）把自己的思路走一遍，哪怕只有五分钟，再去问AI。这样做有两个好处：一是我能更精确地提出问题；二是我有了一个参照系，能真正评估AI给的答案。

**把AI当辩论对手，不当答案机器。** 我开始更多地用AI来"挑战我的方案"，而不是"给我方案"。比如我先想出一个设计，然后让AI帮我找这个设计的漏洞。这样我既保留了独立思考的过程，又能利用AI的信息广度。

**定期做"无AI"的深度思考练习。** 我有时候会刻意地不用AI，坐下来对着一个技术问题死磕。不是因为AI不能帮我，而是因为我需要保持那块肌肉的活跃。写技术博客对我来说也是这种练习——把思路用自己的语言整理出来，本身就是一种对思维能力的锤炼。

**对AI输出保持结构性怀疑。** 我在给自己建立一个习惯：每次AI给出重要的技术建议，我都要花一点时间回答"我为什么相信这个？"。如果我说不清楚，那就是我还没真正理解它。

---

## 写在最后：一个关于"效率"的更大问题

AI让我的工作效率提升了好几倍，这是真实的。但我越来越觉得，"效率"这个词需要被重新定义。

如果效率只是衡量短期内完成任务的速度，那深度依赖AI确实有效率。但如果效率还包括**你在这个过程中积累了多少判断力、建立了多少真正的理解**，那当前的使用方式可能是一种负效率。

我不知道未来五年软件工程师的角色会变成什么样。但我有一个直觉：在一个AI可以完成大量执行任务的世界里，**能够提出好问题、做出好判断、在模糊和复杂中导航**的人，价值只会更高，而不是更低。而这些能力，恰恰是需要靠独立思考来维持的。

所以这篇文章，与其说是一个警告，不如说是一个写给自己的备忘录：**别让工具变成拐杖。保持思考，哪怕它很慢，哪怕它很痛。**

---

*如果你也有类似的感受，欢迎在评论区聊聊你的观察和应对方式。*
